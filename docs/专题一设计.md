# 编译原理实验一

[toc]

### 前言

由于md对latex公式渲染和代码排版和高亮良好支持，我还是选用了md作为实验报告书写格式。并附上了实验报告的封面，将其导出成pdf和word。

`Satori`意味**开悟、顿悟**，我希望能够通过一系列的动手实践让我在学习的过程中收获包括技术和人生方面的感悟，因而为自己设计的编译器冠以此名。

### 一、目标任务

以下为正则文法所描述的 C 语言子集的但此符号的示例，请补充单词符号：++,--,>>,<<,+=,-=,*=,/=,&&,||,!等，**给出补充后描述 C 语言子集单词符号的正则文法，设计并实现其词法分析程序**。
<标识符>→字母 | <标识符>字母 | <标识符>数字
<无符号整数>→数字 | <无符号整数>数字
<单字符分界符>→+ | - | * | ; | , | ( | ) | { | }
<双字符分界符>→<大于>= | <小于>= | <小于>> | <感叹号>= | <等于>= | <斜竖>*
<小于>→<
<等于>→=
<大于>→>
<斜竖>→/
<感叹号>→!
要能够识别语言的保留字：void, int, float, double, if, else, for, do, while 等等（可以补充）

### 二、设计说明

#### 1、补充符号并给出正则文法

**按照实验要求**，我给出补充后的正则文法：

<标识符>→字母<标识符 2>

<标识符 2>→字母<标识符 2> | 数字<标识符 2> | ε

<单字符分界符>→ + | - | * | / | % | = | ( | ) | { | } | [ | ] | < | > | ; | , | . | \ | & | ^ | | | !

<双字符分界符>→ ><等号> | <<等号> | ! <等号> | =<等号> | +<加号> | -<减号> | |<单字符或> | &<单字符与> | *<等号> | /<等号> | +<等号> | -<等号> | %< 等号> | <<小于号> | ><大于号>

<等号>→=

<加号>→+

<减号>→-

<单字符或>→|

<单字符与>→&

<小于号>→<

<大于号>→>

<有符号整数>→+<无符号整数> | -<无符号整数> | 数字<无符号整数>

<有符号浮点数>→+<无符号浮点数> | -<无符号浮点数> | 数字<无符号浮点数>

<行注释>→/<行注释 2>

<行注释 2>→/<行注释 3>

<行注释 3>→任意不是换行符的字符<行注释 3> | 换行符

<块注释>→/<块注释 2>

<块注释 2>→*<块注释 3>

<块注释 3>→任意不是*的字符

<块注释 3> | *<块注释结束判定>

<块注释结束>→/ | 任意不是/的字符<块注释 3>

**事实上，我并未采用上面的方式**。一方面，在关键字的识别方面，我决定**将关键字定义安排到语法分析阶段实现**。针对词法规则的定义，我**采用的是正则表达式**，这主要是受到现代比较成熟的**词法/文法分析器生成器**的做法的启发。针对这样的设计，我额外实现了一个**正则表达式解析引擎**和**NFA构造器**，同时根据文法定义完成了词法分析结果到相应关键字、终结符的**映射**。这样做有许多好处，下面将进行讨论。

#### 2、词法分析器调研

目前市面上有许多成熟的词法分析器生成器，例如

1. Lex：Lex是Unix系统上最常用的词法分析器生成器之一，它可以生成C语言的词法分析器。
2. Flex：Flex是Lex的一个开源替代品，它可以生成C/C++语言的词法分析器。
3. ANTLR：ANTLR是一款用Java编写的词法分析器生成器，它支持多种语言，包括Java、C#、Python等。
4. JFlex：JFlex是Flex的Java版本，它可以生成Java语言的词法分析器。
5. PLY：PLY是Python Lex-Yacc的缩写，它是Python语言的词法分析器和语法分析器生成器。
6. GNU Bison：GNU Bison是一个强大的语法分析器生成器，它可以生成C/C++语言的语法分析器。

其中，Lex是一个生成词法分析器的工具，它可以根据用户定义的正则表达式和对应的操作，自动生成C语言代码，用于对输入的字符串进行词法分析。下面是Lex的使用方法：

1. 定义词法规则：使用正则表达式定义输入字符串的模式，并为每种模式定义相应的操作。例如，以下代码定义了一个识别整数的规则，当匹配到整数时，将其转换为整型并返回。

```
[0-9]+    { return atoi(yytext); }
```

2. 编写Lex源文件：将所有的词法规则写入一个Lex源文件中，并在文件开头添加一些声明和定义，例如：

```
%{
#include <stdio.h>
// C语言声明，一般声明全局变量和函数，会复制进lex.yy.c中
%}

%option noyywrap

%%
// 规则段，每一行都是一条规则，每条规则由匹配模式和事件组成。
// 每当一个模式被匹配后，后面的事件被执行
{规则1}     { 操作1 }
{规则2}     { 操作2 }
...

%%
// 用户自定义的过程，会被复制到lex.yy.c的末尾
int main() {
    yylex();
    return 0;
}
```

其中，`%{` 和 `%}` 之间的代码将被直接复制到生成的C代码中，`%option noyywrap` 表示禁用yywrap函数，`%%` 表示词法规则的开始和结束，`main` 函数中的 `yylex()` 函数将会执行词法分析。

3. 使用Flex生成词法分析器：在命令行中输入 `flex lex_file.l` 命令，将会生成一个名为 `lex.yy.c` 的C语言源代码文件。
4. 编译并运行生成的代码：使用 `gcc -o lex_file lex.yy.c` 命令将C源文件编译为可执行文件，然后运行生成的可执行文件即可进行词法分析。

以上就是Lex的基本用法，通过定义词法规则和操作，可以快速生成一个词法分析器，用于对输入的字符串进行分析。

#### 3、实验大致思路

根据上面的调研，我想挑战一下自己，打算使用正则表达式（RE）来书写声明式的规范，使用NFA和DFA来自动构建词法分析器。

可以以下列五个元素的集合表示一个有限状态机：

$$
A = (S, \sum, \delta, s0, Fs)

S ：状态集合 \newline
\sum：输入的字母表（输入字符的集合） \newline
\delta：状态转移函数，\delta: S \times \sum \to S \newline
s0：初始状态，s0 \in S \newline
F：终止状态，F \subseteq S \newline

一个有限状态机从初始状态s0 出发，到终止状态 F 结束，中间透过输入字符c \in \sum和转移函数 \delta 决定状态的变化。
$$

经过进一步调研，梳理出大致思路如下：

根据实际需求，设计正则文法或正则式，将其转换为正则表达式；

使用 Thompson 算法将正则表达式转换为NFA；

使用子集构造算法将NFA确定化为DFA；

使用 Hopcroft 最小化算法得到最小化的DFA。

### 三、实验步骤

#### 3.0 实验思路浅析

汤普森构造法是C语言&Unix之父之一的肯·汤普森(Ken Thompson)提出的构造识别正则表达式ε-NFA的方法，其原理非常简单，先构造识别子表达式的ε-NFA，再通过几个简单的规则将ε-NFA合并，最终得到识别完整正则表达式的ε-NFA。汤普森构造法的优点是构造速度快，且构造的ε-NFA状态数较少。

#### 3.1 正则表达式的解析和处理

该方法首先需要设计识别并解析正则表达式的程序模块，关于识别正则表达式的具体的实现，大致有两种方法：

**方法一 递归下降法：**

基于对 RE 的结构做归纳，对基本的 RE 直接构造，对复合的 RE 递归构造。其优势是使用递归算法，相对比较容易实现。

**方法二 逆波兰式法：**

将RE转化为后缀表达式，利用栈结构完成对RE的解析。其优势是可以将复杂的表达式转化为能够依靠简单的操作得到计算结果的表达式。

经过斟酌，我决定使用第二种方法。

##### 3.1.1 正则表达式的介绍和约定

正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。

一般来讲，正则表达式支持如下特性：

> 1. 字符组：用方括号 [] 来表示，可以匹配方括号中的任意一个字符。例如 [abc] 可以匹配字符 a、b 或 c。
> 2. 数量词：用来指定匹配的次数，例如 * 表示匹配 0 次或多次，+ 表示匹配 1 次或多次，? 表示匹配 0 次或 1 次，{n} 表示匹配 n 次，{n,m} 表示匹配 n 到 m 次。
> 3. 特殊字符：包括元字符、转义字符和定位符。元字符包括 .、|、() 等，用来表示特定的字符或字符集合。转义字符用来表示特殊字符，例如 \d 表示匹配数字，\s 表示匹配空白字符。定位符用来匹配字符串的位置，例如 ^ 表示匹配字符串的开头，$ 表示匹配字符串的结尾。
> 4. 分组：用圆括号 () 来表示，可以将多个字符组合成一个整体，方便进行匹配和替换。例如 (ab)+ 表示匹配一个或多个连续的 ab。
> 5. 前后查找：用来匹配某个字符前面或后面的字符。例如 (?<=a)b 表示匹配前面是 a 的 b，(?=a)b 表示匹配后面是 a 的 b。
> 6. 贪婪匹配和非贪婪匹配：默认情况下，正则表达式会尽可能地匹配更多的字符，这种匹配方式称为贪婪匹配。如果在量词后面加上 ?，则表示非贪婪匹配，即尽可能少地匹配字符。

在本次实验过程中，我会实现一个**简易的正则表达式的解析引擎**，其所支持的功能是标准正则表达式功能的**子集**，具体功能约定如下（命名并不规范，仅作理解用）：

1. **字符组、字符区间、反选字符**：用方括号 `[]`表示字符组，匹配方括号中的**任意**一个字符。形如 `a-z`、`0-9`的字符子串表达一个字符**区间**。左方括号后紧跟一个 `^`表达对字符组所确定的字符进行**反选**，即有效字符的**全集**减去字符组内的字符得到的新字符组。
2. **转义字符、等价字符、通配符**：以转义字符 `\`开头的字符将会被转义，例如操作符 `+`被转移后就失去了操作符的含义，可用于表达对加号的匹配。特别的，`\e`等价于符号$\epsilon$，`\d`等价于 `0-9`，`\a`等价于 `a-zA-Z`，`\w`等价于 `a-zA-Z0-9_`，`\s`代表所有的空白字符，等等。`.`代表通配符，即接受有效字符的全集。
3. **单目操作符**：我实现的简易的正则表达式支持四种基本的单目操作符（均只接受**左目参数**）。`^`代表连接符（省略不写，分析程序会自动加上，无需转义）；`?`代表可选符，其之前的字符可以出现一次或零次；`+`代表正闭包，其之前的字符应至少出现一次；`*`代表闭包符，其之前的字符可以出现零次、一次或多次。
4. **双目操作符**：目前仅支持一种双目操作符 `|`，表示该操作符两边的内容是或的关系，该操作符相比上述操作符的**优先级最低**。
5. **分组**：支持使用 `()`提升圈中部分的字符的处理优先级，被圈中的字符集会被视为一个整体参与后续的计算。

正则表达式涉及到对ASCII字符串的解析，首先可以将ASCII字符大致分为两类，一类是供正则表达式引擎识别的**普通字符**，另一类则是表达正则表达式语义的**特殊字符**。其中，特殊字符主要包含**运算符**和**转义字符**。

我定义的运算符字符、结合性及优先级如下：

```C++
set<char> leftOp = { // 左结合运算符
    STAR,
    PLUS,
    QUES,
    PARENT_R};
set<char> rightOp = { // 右结合运算符
    PARENT_L};
set<char> doubleOp = { // 双目运算符
    SELECT,
    CONCAT,
};
// 算符优先级
map<char, int> precedence = {
    {STAR, 3},
    {PLUS, 3},
    {QUES, 3},
    {CONCAT, 2},
    {SELECT, 1},
};
```

除了运算符之外，我设计的正则引擎还支持如下转义字符的识别：

```C++
map<char, char> escape = {
    {'n', '\n'},
    {'t', '\t'},
    {'r', '\r'},
    {'f', '\f'},
    {'v', '\v'},
    {'\\', '\\'},
    {'.', '.'},
    {'^', '^'},
    {'?', '?'},
    {'*', '*'},
    {'+', '+'},
    {'|', '|'},
    {'(', '('},
    {')', ')'},
    {'[', '['},
    {']', ']'},
    {'e', EPSILON}, // 空串
    {'a', ALPHA},	// 字母集合
    {'d', DIGIT},	// 数字集合
    {'w', WORD},	// 字母、数字和下划线
    {'s', SPACE},	// 空白字符
    {'S', NON_SPACE}, // 非空字符
};
```

此外，还有一些特殊字符表达特定的作用，在此不再赘述。

##### 3.1.2 正则表达式的预处理

我的正则引擎首先会对正则表达式做一步预处理，这么做的最核心的原因是，将正则表达式转化为**整齐**的**中缀表达式**。所谓整齐，我给的定义就是指表达式中的所有**表达特定语义的单元**都必须是**单个字符**，以方便后续的解析处理。举例而言，正则表达式中范围选择语义`[0-9]`是多个字符，经过预处理后会变成一个不可见的单字符，这里用`SET`表示（预处理器会将诸如 `[0-9a-z_]`的语法先行解析，并预先存储到 `setStates`中备用）。类似的，`\e`要被处理为`EPSILON`，`\+`要被处理为`+`（因为不经转义的`+`会被识别为运算符）。

此外，为了方便后续处理，预处理器会根据字符的结合性在字符之间添加**连接符**`CONCAT`。

例如，对于正则表达式：

```reStructuredText
(\-|\+|\e)[0-9]+
```

预处理器会将其转换为：

`PARENT_L`-`SELECT`+`SELECT` `EPSILON` `PARENT_R` `CONCAT` `SET` `PLUS`

经过上述处理，正则表达式变成了一个方便进一步处理的**中缀表达式**。

核心算法：

```C++
void RegexpParser::regexpPreproc()
{
	info << "regexpPreproc: " << exp2str(rawReg) << endl;
	Viewer rawView(rawReg);
	string tmpStr;
	while (!rawView.ends())
	{
		char c = rawView.step();
		if (c == '\\')
		{
			c = parseEscape(rawView);
			tmpStr.push_back(c);
		}
		else if (c == '[')
		{
			int st = rawView.getPos();
			while (!rawView.ends() && (rawView.step() != ']' || rawView.peek(-2) == '\\'))
				;
			string setExp = rawReg.substr(st, rawView.getPos() - st - 1);
			parseSet(setExp);
			tmpStr.push_back(SET);
		}
		else if (chr2op.find(c) != chr2op.end()) // operator
		{
			tmpStr.push_back(chr2op[c]);
		}
		else // plain symbol
		{
			tmpStr.push_back(c);
		}
	}
	tmpReg.clear();
	Viewer tmpView(tmpStr);
	// 为了方便处理，将正则表达式中的所有非操作符字符之间插入连接符
	while (!tmpView.ends())
	{
		char c = tmpView.step();
		// 所有非操作符字符之间插入连接符
		if (!tmpView.ends() && !_find(opSet, c) && !_find(opSet, tmpView.peek()))
		{
			debug(1) << "insert concat between two symbols " << endl;
			tmpReg.push_back(c);
			tmpReg.push_back(CONCAT);
		}
		// + ? * ) 右边插入连接符
		else if (!tmpView.ends() && _find(leftOp, c) && !_find(leftOp, tmpView.peek()) && !_find(doubleOp, tmpView.peek()))
		{
			debug(1) << "insert concat after + ? * ) " << endl;
			tmpReg.push_back(c);
			tmpReg.push_back(CONCAT);
		}
		// ( 左边插入连接符
		else if (tmpView.getPos() > 1 && _find(rightOp, c) && !_find(rightOp, tmpView.peek(-2)) && !_find(doubleOp, tmpView.peek(-2)))
		{
			debug(1) << "insert concat before ( " << endl;
			if (tmpReg.back() != CONCAT)
			{
				tmpReg.push_back(CONCAT);
			}
			tmpReg.push_back(c);
		}
		else
		{
			tmpReg.push_back(c);
		}
	}
}
```



##### 3.1.3 中缀表达式转后缀表达式

为了方便利用**栈**对表达式进行解析，同时构建NFA，我需要将中缀表达式转化为后缀表达式。

例如，对于正则表达式：

```
>=|<=|!=|==|\+\+|\-\-|\|\||&&|\*=|/=|\+=|\-=|%=|<<|>>
```

经过**预处理**得到：

.>`CONCAT`=`SELECT`<`CONCAT`=`SELECT`!`CONCAT`=`SELECT`=`CONCAT`=`SELECT`+`CONCAT`+`SELECT`-`CONCAT`-`SELECT`|`CONCAT`|`SELECT`&`CONCAT`&`SELECT`*`CONCAT`=`SELECT`/`CONCAT`=`SELECT`+`CONCAT`=`SELECT`-`CONCAT`=`SELECT`%`CONCAT`=`SELECT`<`CONCAT`<`SELECT`>`CONCAT`>

进一步转化为**后缀表达式**得到：

\>=`CONCAT`<=`CONCAT` `SELECT`!=`CONCAT` `SELECT`==`CONCAT` `SELECT`++`CONCAT` `SELECT`--`CONCAT` `SELECT`||`CONCAT` `SELECT`&&`CONCAT` `SELECT`*=`CONCAT` `SELECT`/=`CONCAT` `SELECT`+=`CONCAT` `SELECT`-=`CONCAT` `SELECT`%=`CONCAT` `SELECT`<<`CONCAT` `SELECT`>>`CONCAT` `SELECT`

核心算法：

```C++
void RegexpParser::tmpReg2postfix()
{
	info << "tmpReg2postfix: " << exp2str(tmpReg) << endl;
	stack<char> opStack;
	try
	{
		for (int i = 0; i < tmpReg.size(); i++)
		{
			char c = tmpReg[i];
			if (op2str.find(c) != op2str.end() && c != UNI) // operator
			{
				if (c == STAR || c == PLUS || c == QUES) // single operand operators
				{
					postfix.push_back(c);
				}
				else if (c == PARENT_L)
				{
					opStack.push(c);
				}
				else if (c == PARENT_R)
				{
					while (opStack.top() != PARENT_L)
					{
						postfix.push_back(opStack.top());
						opStack.pop();
					}
					opStack.pop();
				}
				else // binary operand operators
				{
					while (!opStack.empty() && precedence[opStack.top()] >= precedence[c])
					{
						postfix.push_back(opStack.top());
						opStack.pop();
					}
					opStack.push(c);
				}
			}
			else // symbol
			{
				postfix.push_back(c);
			}
		}
		while (!opStack.empty())
		{
			postfix.push_back(opStack.top());
			opStack.pop();
		}
	}
	catch (const exception &e)
	{
		error << "tmpReg2postfix failed. Make sure the regexp is valid." << endl;
		throw e;
	}
}
```



#### 3.2 利用汤普森方法构造NFA

经过以上步骤，就可以开始将正则表达式构造为NFA了。

首先定义NFA的数据结构：

```C++
typedef int state_id_t;
typedef pair<state_id_t, state_id_t> sub_nfa_t;
typedef unordered_map<char, set<state_id_t>> transition_map_t;
/**
 * @brief 非确定的有限状态自动机
 */
class FiniteAutomaton
{
    struct State
    {
        state_id_t id;
        bool isFinal; // 是否为终态
        State(state_id_t id, bool isFinal) : id(id), isFinal(isFinal) {}
    };
    state_id_t startState = 0;                               // 开始状态
    vector<State> states;                                    // 状态集合
    unordered_map<state_id_t, transition_map_t> transitions; // 转移函数

public:
    FiniteAutomaton() {}
    int addState(bool isFinal = false);                                // 添加状态
    void setStartState(state_id_t id);                                 // 设置开始状态
    void setState(state_id_t id, bool isFinal);                        // 设置状态（是否为终态）
    void addTransition(state_id_t from, state_id_t to, char symbol);   // 添加转移
    bool accepts(Viewer &view, string &result, state_id_t start = -1); // 从指定状态开始匹配，递归地匹配每个字符，直到无法匹配为止
    void print();                                                      // 打印自动机的状态和转移函数

    vector<State> getStates()
    {
        return states;
    }

    unordered_map<int, transition_map_t> getTransitions()
    {
        return transitions;
    }
};
```

具体实现请参考源码，在此不做赘述。

##### 3.2.1 汤普森构造法浅析

汤普森构造法是一种将正则表达式转换为NFA的方法。其基本思想是，将正则表达式中的每个字符或操作符转换为一个NFA，并通过连接和或操作符将它们组合起来。

具体步骤如下：

 1、对于正则表达式中的每个字符，构造一个只有两个状态的NFA。该NFA有一个转移边，标记为该字符。
 2、对于正则表达式中的连接（`CONCAT`）操作符，将前一个NFA的终止状态连接到后一个NFA的起始状态。
 3、对于正则表达式中的或操作符（`SELECT`），构造一个新的起始状态和一个新的终止状态，并将前一个NFA和后一个NFA分别连接到这两个状态。
 4、对于正则表达式中的闭包（`STAR`）操作符，构造一个新的起始状态和一个新的终止状态，并将原来的NFA连接到这两个状态。然后，将新的起始状态连接到原来的起始状态和新的终止状态，将原来的终止状态连接到原来的起始状态和新的终止状态。
 5、最终的NFA的起始状态为正则表达式的起始状态，终止状态为正则表达式的终止状态。

 <center>
 	<img src="https://img-blog.csdnimg.cn/img_convert/c19e51dab02f142d16b1210ce713575f.png" width="15%"></img>
 	<img src="https://img-blog.csdnimg.cn/img_convert/3bf9d5f046ce7566697d833f14fd1bd0.png" width="20%"></img>
 	<img src="https://img-blog.csdnimg.cn/img_convert/92d5f471bf9a9bfa86fc5e613848949d.png" width="20%"></img>
 	<img src="https://img-blog.csdnimg.cn/img_convert/1f371a8ed4399a9f7a69daa6ad4a0f32.png" width="25%"></img>
 </center>

类似的还可以实现`PLUS`、`QUES`等操作符，不再赘述。

通过以上步骤，我们就可以将正则表达式转换为一个NFA。

##### 3.2.2 后缀表达式的处理

我才用栈的方式处理上述步骤得到的后缀表达式，针对每一个遇到的运算符，其对应的栈操作定义如下：

```C++
// 选择运算符 | SELECT
void RegexpParser::opSelect()
{
	// (st1, ed1) (st2, ed2) | => (nst, ned)
	sub_nfa_t sub2 = nfaStack.top();
	int ed2 = sub2.second;
	int st2 = sub2.first;
	nfa.setState(ed2, false);
	nfaStack.pop();
	sub_nfa_t sub1 = nfaStack.top();
	int ed1 = sub1.second;
	int st1 = sub1.first;
	nfa.setState(ed1, false);
	nfaStack.pop();
	int nst = nfa.addState();
	int ned = nfa.addState(true);
	nfa.addTransition(nst, st1, EPSILON);
	nfa.addTransition(nst, st2, EPSILON);
	nfa.addTransition(ed1, ned, EPSILON);
	nfa.addTransition(ed2, ned, EPSILON);
	nfaStack.push(make_pair(nst, ned));
}
// 闭包运算符 * STAR
void RegexpParser::opStar()
{
	// (st, ed) * => (nst, ned)
	sub_nfa_t sub = nfaStack.top();
	int ed = sub.second;
	int st = sub.first;
	nfa.setState(ed, false);
	nfaStack.pop();
	int nst = nfa.addState();
	int ned = nfa.addState(true);
	nfa.addTransition(nst, st, EPSILON);
	nfa.addTransition(nst, ned, EPSILON);
	nfa.addTransition(ed, st, EPSILON);
	nfa.addTransition(ed, ned, EPSILON);
	nfaStack.push(make_pair(nst, ned));
}
// 正闭包运算符 + PLUS
void RegexpParser::opPlus()
{
	// (st, ed) + => (nst, ned)
	sub_nfa_t sub = nfaStack.top();
	int ed = sub.second;
	int st = sub.first;
	nfa.setState(ed, false);
	nfaStack.pop();
	int nst = nfa.addState();
	int ned = nfa.addState(true);
	nfa.addTransition(ed, st, EPSILON);
	nfa.addTransition(nst, st, EPSILON);
	nfa.addTransition(ed, ned, EPSILON);
	nfaStack.push(make_pair(nst, ned));
}
// 可选运算符 ? QUES
void RegexpParser::opQues()
{
	// (st, ed) ? => (nst, ned)
	sub_nfa_t sub = nfaStack.top();
	int ed = sub.second;
	int st = sub.first;
	nfa.setState(ed, false);
	nfaStack.pop();
	int nst = nfa.addState();
	int ned = nfa.addState(true);
	nfa.addTransition(nst, st, EPSILON);
	nfa.addTransition(nst, ned, EPSILON);
	nfa.addTransition(ed, ned, EPSILON);
	nfaStack.push(make_pair(nst, ned));
}
// 连接运算符 CONCAT
void RegexpParser::opConcat()
{
	// (st1, ed1) (st2, ed2) ~ => (st1, ed2)
	sub_nfa_t sub2 = nfaStack.top();
	int ed2 = sub2.second;
	int st2 = sub2.first;
	nfaStack.pop();
	sub_nfa_t sub1 = nfaStack.top();
	int ed1 = sub1.second;
	int st1 = sub1.first;
	nfa.setState(ed1, false);
	nfaStack.pop();
	nfa.addTransition(ed1, st2, EPSILON);
	nfaStack.push(make_pair(st1, ed2));
}
```

关于栈的解析方面，上面操作符的定义已经能说明大部分问题，而负责调用这些运算符的函数则需要考虑非常多的情况，因而并不适合粘贴在报告中，在此，我简单给出该函数的**最核心**部分，其余代码请前往源码中参阅。

```C++
else if (op2str.find(c) != op2str.end() && c != UNI) // operator
		{
			debug(0) << "postfix2FA: Executing " << op2str[c] << endl;
			switch (c)
			{
			case CONCAT:
				opConcat();
				break;
			case QUES:
				opQues();
				break;
			case STAR:
				opStar();
				break;
			case PLUS:
				opPlus();
				break;
			case SELECT:
				opSelect();
				break;
			}
		}
```

部分执行过程截图如下：

![image-20230416234823336](D:\课程文档\大三下\课程作业\编译\Lab1\assets\image-20230416234823336.png)

得到如下所示的NFA：

![image-20230416234900400](D:\课程文档\大三下\课程作业\编译\Lab1\assets\image-20230416234900400.png)

#### 3.3 词法分析器的简单实现

##### 3.3.1 词法分析器的规则定义

参照LEX的做法，我设计了自己的词法定义文件格式（`.lex`文件），示例如下：

```C++
PATTERN ${
    BLANK       \s+
    START       \*
    COMMENT     //[^\r\n]*
    EPSILON     \\e
    CONSTANT    REAL|INTEGER|STRING
    IDENTIFIER  IDENTIFIER
    NON_TERM    [\a_][\w']*
    TERMINAL    `[^`]*`
    DEFINITION  ::=
    SEPARATOR   [\(\){}\[\]\|;]
$}

IGNORE ${
    BLANK
    COMMENT
$}
```

其中，`PATTERN`所代表的定义块定义了词法的**类型**和对应的**正则表达式**描述，`IGNORE`所代表的定义块定义了指示词法分析器**忽略**掉的词素，例如，上面的示例指示词法分析器忽略类型为`BLANK`和`COMMENT`的词素，而不要将其传递给后续的编译流程。

##### 3.3.2 对单条规则的解析处理

我为NFA添加了 `accepts`函数，负责检测传入的字符串是否能被接受。该函数主要采取**递归调用**的方式，每次递归向前接受一个字符，若无法接受则回溯至接受的状态，直至找到**最长的匹配前缀**或者匹配失败。我将3.3.1所述的每一条规则都构造一个与之对应的NFA，这样便实现了单条规则的解析处理。

```C++
/**
 * @brief 从指定状态开始匹配，递归地匹配每个字符，直到无法匹配为止
 *
 * @param view 		所需匹配的字符串视图，每次匹配一个字符，匹配成功后视图向后移动一位
 * @param result 	匹配成功后的结果，如果匹配失败则为""
 * @param start 	起始状态
 * @return true		匹配成功
 * @return false	匹配失败
 */
bool FiniteAutomaton::accepts(Viewer &view, string &result, state_id_t start)
{
	if (start == -1) // 未指定起始状态，使用默认起始状态
		start = startState;
	if (states[start].isFinal) // 如果当前状态为终态，返回true
	{
		return true;
	}
	Viewer subView = view; // 保存当前视图，用于回溯
	if (transitions.find(start) != transitions.end())
	{
		char c = subView.step(); // 获取当前字符，视图向后移动一位
		transition_map_t available = transitions[start];
		bool resFlag = false;
		string tmpRes;			  // 保存当前匹配结果
		Viewer tmpView = subView; // 保存当前视图，用于回溯
		if (available.find(c) != available.end())
		{
			set<state_id_t> nextSet = available[c];
			for (auto i : nextSet)
			{
				string nxtRes;
				Viewer vNext = subView;
				if (accepts(vNext, nxtRes, i) && vNext >= tmpView)
				{
					resFlag = true;
					tmpRes = nxtRes;
					tmpView = vNext;
				}
			}
			if (resFlag)
			{
				result = c + tmpRes;
				view = tmpView;
				return true;
			}
		}
		if (c != EPSILON && available.find(EPSILON) != available.end())
		{
			subView.skip(-1); // EPSILON转移不消耗字符，视图回退一位
			tmpView = subView;
			set<state_id_t> nextSet = available[EPSILON];
			for (auto i : nextSet)
			{
				string nxtRes;
				Viewer vNext = subView;
				if (accepts(vNext, nxtRes, i) && vNext >= tmpView)
				{
					resFlag = true;
					tmpRes = nxtRes;
					tmpView = vNext;
				}
			}
			if (resFlag)
			{
				result = tmpRes;
				view = tmpView;
				return true;
			}
		}
	}
	return false;
}
```

##### 3.3.3 多条词法分析规则的处理

上面给出的方法只能处理单条规则，而要支持多条规则的选择性匹配，并能够解析源代码，就必须考虑多条词法规则的组合实现。在这里，我的实现方法比较简单粗暴，核心思路就是针对当前输入流依次使用不同规则定义的NFA尝试匹配，并取最长的匹配结果作为接受的`Token`。

首先设计词法分析器结构如下：

```C++
class Lexer
{
    set<token_type_t, type_less> ignoredTypes;
    vector<token_type_t> typeOrder;                              // 词法单元类型顺序
    map<token_type_t, vector<FiniteAutomaton>, type_less> faMap; // 状态自动机对照表
    void readLexerDef(string fileName);

public:
    Lexer() {}
    Lexer(string lexPath)
    {
        readLexerDef(lexPath);
    }
    void addTokenType(string typeName, string regExp);
    void addIgnoredType(string typeName);
    vector<token> tokenize(string fileName);
    void printTokens(vector<token> tokens);
    void clear();
};
```

详细实现不多赘述，下面直接给出核心的词法解析实现：

```C++
vector<token> Lexer::tokenize(string fileName)
{
    ifstream ifs(fileName);
    assert(ifs.is_open(), "File not found: " + fileName);
    string code(
        (istreambuf_iterator<char>(ifs)),
        (istreambuf_iterator<char>()));
    ifs.close();
    info << "Code: " << endl;
    cout << code << endl;
    info << "Tokenizing... " << endl;
    vector<token> tokens;
    code_viewer vCode(code);
    while (!vCode.ends())
    {
        bool matched = false;
        string matchedToken;
        token_type_t matchedType;
        Viewer matchedView = vCode;
        for (auto typ : typeOrder) // 按序遍历所有的状态自动机
        {
            const auto &faVec = faMap[typ];
            for (auto nfa : faVec)
            {
                Viewer vTmp = vCode;
                string matchResult;
                if (nfa.accepts(vTmp, matchResult))
                {
                    if (matchResult.length() > matchedToken.length()) // 同类型的自动机取匹配的最长词法单元
                    {
                        matchedToken = matchResult;
                        matchedType = typ;
                        matchedView = vTmp;
                        matched = true;
                    }
                }
            }
            if (matched) // 按照顺序，一旦有某种类型的自动机匹配成功，就不再匹配其他类型的自动机
                break;
        }
        if (matched)
        {
            matchedToken = zTrim(matchedToken); // 补丁：去掉末尾的空字符，产生原因未知
            vCode = matchedView;
            if (!_find(ignoredTypes, matchedType))
            {
                // 忽略空白和注释，其他的都作为词法单元
                int line, col;
                tie(line, col) = vCode.getCurLineCol();
                tokens.push_back(
                    token(matchedType, matchedToken, line, col));
            }
            debug(0) << format("Matched: $ <$>", matchedToken, matchedToken.size()) << endl;
        }
        else
        {
            auto lc = vCode.getCurLineCol();
            error << "Tokenize failed at <" << lc.first << ", " << lc.second << ">" << endl;
            // 打印出错位置的上下文
            vCode.printCodeCtx();
            vCode.skipToNextLine();
        }
    }
    return tokens;
}
```

#### 3.4 一些细节的说明和讨论

**由于时间原因，下面的内容尚未完善。请您先行跳过。**

使用共享智能指针作为种别码

##### 3.4.1 分级日志的设计实现

##### 3.4.2 字符串浏览器的设计实现

##### 3.4.3 匹配策略的相关思考

DFA可以确保匹配最长的可能的字符串（最长前缀），但不能捕获子表达式。相应的，NFA一般采取贪婪的匹配回溯策略，以正则表达式指定的顺序测试所有可能的扩展并接受最长的匹配项。

##### 3.4.4 NFA和DFA的相关思考

在最坏的情况下，NFA回溯可能产生极深的递归，并导致速度的显著下降

终止条件的分析，贪婪性，循环和早停

关于匹配策略的简单讨论和实现（最长前缀匹配和完全匹配）

词法分析器的分类匹配策略和错误处理策略

##### 3.4.5 词法/语法分析器的职责讨论

词法分析阶段不确定关键字

由文法定义所需的关键字和映射关系

词法分析结果需要进行一步映射和转化

### 四、测试用例

首先给出词法定义，此处我直接参照C语言的相关约定，除了实现基本的**空白、注释、标识符、分隔符**等的识别外，我还实现了**整型、浮点型、科学计数法、正负数、字符串、块注释**等词法类别的识别：

```
PATTERN ${
    BLANK       \s+
    LIN_CMT     //[^\r\n]*
    BLK_CMT     /\*([^\*]|\*[^/])*\*/
    MACRO       #[\w]+
    INCLUDE     "[\w.]+"|<[\w.]+>
    IDENTIFIER  [\a_][\w]*
    STRING      "[^"]*"
    CHARACTER   '.'
    REAL        (\-|\+|\e)[\d]+\.[\d]+(\e|e(\-|\+|\e)[\d]+)
    REAL        (\-|\+|\e)0[bB][01]+\.[01]+(e(\-|\+|\e)[\d]+)?
    REAL        (\-|\+|\e)0[oO][0-7]+\.[0-7]+(e(\-|\+|\e)[\d]+)?
    REAL        (\-|\+|\e)0[xX]([\da-fA-F]+|[\d]+)\.([\da-fA-F]+|[\d]+)(e(\-|\+|\e)[\d]+)?
    INTEGER     (\-|\+|\e)[\d]+(e(\-|\+|\e)[\d]+)?
    INTEGER     (\-|\+|\e)0[bB][01]+(e(\-|\+|\e)[\d]+)?
    INTEGER     (\-|\+|\e)0[oO][0-7]+(e(\-|\+|\e)[\d]+)?
    INTEGER     (\-|\+|\e)0[xX]([\da-fA-F]+|[\d]+)(e(\-|\+|\e)[\d]+)?
    SEPARATOR   [\+\-\*\\%=\(\){}\[\]<>;,.\|&^!:~\?]
    SEPARATOR   >=|<=|!=|==|\+\+|\-\-|\|\||&&|\*=|/=|\+=|\-=|%=|<<|>>|::|->
$}

IGNORE ${
    BLANK
    LIN_CMT
    BLK_CMT
$}
```

给出正确的测试样例：

```C++
#include <iostream> // header file
using namespace std;

// testing function
int test()
{

    int x = 10;                // integer variable
    int y = +3e10;             // integer variable in scientific notation
    int z = 0x3f;              // integer variable in hexadecimal notation
    float o = 3.14;            // float variable
    double p = -2.71828;       // double variable
    double q = 1.0e-10;        // double variable in scientific notation
    char c = 'a';              // character variable
    string s = "Hello World!"; // string variable

    cout << "x = " << x << endl;

    int result = x + 2 * (y - z);
    cout << "result = " << result << endl;

    if (x > y)
    {
        cout << "x is greater than y." << endl;
    }
    else
    {
        cout << "x is less than or equal to y." << endl;
    }

    /*
    block comment 1
    */

    for (int i = 0; i < x; i++)
    {
        cout << i << " "; /* block comment 2 */
    }
    cout << endl;

    // line comment

    return 0;
}
```

可见上述测试用例基本涵盖了许多常见的词法特性，程序运行结果如下：

正则表达式解析和NFA构造阶段：

![image-20230525232726973](D:\CodeBase\C++Prjs\SatoriCompiler\docs\assets\image-20230525232726973.png)

词法分析识别阶段：

![image-20230525232747335](D:\CodeBase\C++Prjs\SatoriCompiler\docs\assets\image-20230525232747335.png)

词法分析结果：

![image-20230525232829548](D:\CodeBase\C++Prjs\SatoriCompiler\docs\assets\image-20230525232829548.png)

![image-20230525232844167](D:\CodeBase\C++Prjs\SatoriCompiler\docs\assets\image-20230525232844167.png)

可见，程序运行正常。

下面使用错误用例：

针对词法错误，我选择的处理方式是直接跳过改行，从下一行开始继续处理，同时输出报告出错位置，效果如下：

![image-20230525233140177](D:\CodeBase\C++Prjs\SatoriCompiler\docs\assets\image-20230525233140177.png)

### 五、实验总结

本次专题实验，我编写了一个正规式转换为 NFA 的程序，将能够识别 C 语言词法的正规式转换为 NFA，用于扫描器进行词法分析。

### 六、代码说明

#### 6.1 代码开源

本次实验及后续实验所涉及到的代码均共享同一个项目框架，且源码开源在Github。

Github开源链接：https://github.com/Kogler7/SatoriCompiler

#### 6.2 代码结构

根目录

- `assets`：资源文件夹，例如测试用的源代码，以及词法分析器、语法分析器（目前还没有）的配置文件
- `docs`：说明文档，目前主要放实验报告及相关截图
- `src`：源代码文件夹
  - `codegen`：目标代码生成模块（暂时还没有）
  - `lexer`：词法分析器模块（本次实验主角）
  - `parser`：语法分析器模块（暂时还没有）
  - `utils`：模块间共享的一些工具模块
  - `main.cpp`：程序主入口文件
- `CMakeList`：CMake说明
- `LICENSE`：开源协议（MIT）
- `README.md`：其他说明
